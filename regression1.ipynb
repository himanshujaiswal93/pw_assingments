{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q.1 What is Simple Linear Regression \n",
    "\n",
    "Simple Linear Regression is a statistical method that models the linear relationship between two variables: one independent variable (X) and one dependent variable (Y). It predicts ùëå\n",
    "Y based on the equation:  Y=mX+c\n",
    "where \n",
    "m is the slope, and \n",
    "c is the intercept.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q>2 What are the key assumptions of Simple Linear Regression\n",
    "\n",
    "Linearity: The relationship between ùëã and Y is linear.\n",
    "Independence: Observations are independent of each other.\n",
    "Homoscedasticity: The variance of residuals is constant across all levels of X.\n",
    "Normality of Residuals: The residuals (differences between observed and predicted (Y) follow a normal distribution.\n",
    "No Multicollinearity: Not applicable here as there is only one predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q>3 What does the coefficient m represent in the equation Y=mX+c\n",
    "\n",
    "the slop (m) is reprsent the rate of change of (Y) with rerspect to (X).\n",
    "Specifically, m is the change in Y for a one-unit increase in X.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.4 What does the intercept c represent in the equation Y=mX+c\n",
    "\n",
    "The intercept (c) is the value of ùëå when X=0.\n",
    "It represents the starting point of the regression line on the Y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.6 What is the purpose of the least squares method in Simple Linear Regression\n",
    "\n",
    "The least squares method minimizes the sum of squared differences (residuals) between the observed values and the predicted values. It ensures the best-fitting line for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.7 How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression\n",
    "\n",
    "R 2  measures the proportion of the variance in the dependent variable (Y) explained by the independent variable (X). It ranges from 0 to 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.8 What is Multiple Linear Regression\n",
    "\n",
    "Multiple Linear Regression models the relationship between one dependent variable and two or more independent variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.9  What is the main difference between Simple and Multiple Linear Regression?\n",
    "\n",
    "Simple Linear Regression: One independent variable.\n",
    "Multiple Linear Regression: Two or more independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.10 Simple Linear Regression: One independent variable.\n",
    "Multiple Linear Regression: Two or more independent variables.\n",
    "\n",
    "Linearity of relationships.\n",
    "Independence of observations.\n",
    "Homoscedasticity.\n",
    "Normality of residuals.\n",
    "No multicollinearity among independent variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.11 What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
    "\n",
    "Heteroscedasticity occurs when the variance of residuals is not constant across all levels of predictors. It can lead to biased standard errors, invalidating statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.12 How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "\n",
    "Remove highly correlated predictors.\n",
    "Use dimensionality reduction techniques (e.g., PCA).\n",
    "Apply regularization methods like Ridge or Lasso regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.13 What are some common techniques for transforming categorical variables for use in regression models?\n",
    "\n",
    "One-hot encoding.\n",
    "Label encoding.\n",
    "Binary encoding.\n",
    "Frequency or count encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.14 What is the role of interaction terms in Multiple Linear Regression?\n",
    "\n",
    "Interaction terms account for the combined effect of two or more predictors on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.15 How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "\n",
    "Simple Regression: The value of \n",
    "ùëå\n",
    "Y when \n",
    "ùëã\n",
    "=\n",
    "0\n",
    "X=0.\n",
    "Multiple Regression: The value of \n",
    "ùëå\n",
    "Y when all predictors are 0, which might not always be meaningful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.16 What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "\n",
    "The slope indicates the strength and direction of the relationship between a predictor and the outcome. A higher absolute slope means a stronger effect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.17 How does the intercept in a regression model provide context for the relationship between variables?\n",
    "\n",
    "The intercept gives the baseline value of the dependent variable when all predictors are zero, contextualizing the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.18 What are the limitations of using ùëÖ2  as a sole measure of model performance?\n",
    "\n",
    "ùëÖ2doesn‚Äôt account for overfitting.\n",
    "It doesn‚Äôt indicate how well the model predicts unseen data.\n",
    "High ùëÖ2 doesn‚Äôt imply causation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.19 How would you interpret a large standard error for a regression coefficient?\n",
    "\n",
    "A large standard error suggests the coefficient estimate is imprecise, often due to small sample size, high variability, or multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.20 How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "\n",
    "Heteroscedasticity appears as a funnel shape in residuals vs. fitted values plots. Addressing it is crucial to ensure valid statistical tests and confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.21  What does it mean if a Multiple Linear Regression model has a high ùëÖ2\n",
    "\n",
    "\n",
    "It indicates that some predictors in the model do not contribute significantly, potentially causing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.22 Why is it important to scale variables in Multiple Linear Regression?\n",
    "\n",
    "Scaling ensures that variables with larger ranges don‚Äôt dominate the regression coefficients, improving model interpretability and numerical stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.23  What is polynomial regression?\n",
    "\n",
    "\n",
    "\n",
    "Polynomial regression models non-linear relationships between X and ùëå by adding polynomial terms to the equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.24  How does polynomial regression differ from linear regression?\n",
    "\n",
    "Linear Regression: Models linear relationships.\n",
    "Polynomial Regression: Models non-linear relationships by including higher-order terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.25  When is polynomial regression used?\n",
    "Polynomial regression is used when the relationship between the dependent variable (\n",
    "Y) and the independent variable(s) (X) is non-linear but can be approximated by a polynomial function. It is commonly applied in situations where:\n",
    "\n",
    "A linear model is insufficient to capture the underlying trends.\n",
    "The data exhibits curvature.\n",
    "Non-linear patterns can be approximated using polynomial terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.26 What is the general equation for polynomial regression?\n",
    "\n",
    "\n",
    " polynomial regression can include interaction terms and polynomial terms for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.27 Can polynomial regression be applied to multiple variables?\n",
    "\n",
    "Yes, polynomial regression can be extended to multiple variables by including polynomial terms for each varible  and their interactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.28 What are the limitations of polynomial regression?\n",
    "\n",
    "Overfitting: High-degree polynomials may fit the training data too well, leading to poor generalization.\n",
    "Extrapolation issues: Predictions outside the range of the data can become highly inaccurate.\n",
    "Complexity: Higher-degree polynomials increase model complexity, making interpretation difficult.\n",
    "Multicollinearity: Polynomial terms can be highly correlated, affecting the stability of the model coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.29 What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "\n",
    "Cross-validation: Evaluate the model‚Äôs performance on validation data to avoid overfitting.\n",
    "Residual analysis: Check residual plots to ensure no patterns remain.\n",
    "\n",
    "Adjusted \n",
    "R2: Use adjusted ùëÖ2to account for additional terms in the model.\n",
    "AIC/BIC: Use Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC) for model selection.\n",
    "Error metrics: Evaluate metrics like Mean Squared Error (MSE) or Root Mean Squared Error (RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.30 Why is visualization important in polynomial regression?\n",
    "Visualization helps:\n",
    "\n",
    "Detect non-linear trends in the data that justify using polynomial regression.\n",
    "Understand how well the model fits the data by plotting the polynomial curve against the actual data points.\n",
    "Identify overfitting or underfitting by visualizing the residuals or comparing training and testing data fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Q.31 How is polynomial regression implemented in Python?\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "#Q.31 How is polynomial regression implemented in Python?\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Example data\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "y = np.array([1, 4, 9, 16, 25])\n",
    "\n",
    "# Transform features to polynomial terms\n",
    "degree = 2  # Degree of the polynomial\n",
    "poly = PolynomialFeatures(degree)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Fit the polynomial regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "\n",
    "# Predict using the model\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X, y_pred, color='red', label='Polynomial Fit')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
